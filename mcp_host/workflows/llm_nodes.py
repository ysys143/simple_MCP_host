"""LLM ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ë…¸ë“œ

OpenAI ChatGPTë¥¼ í™œìš©í•˜ì—¬ ìì—°ì–´ ì´í•´ì™€ ì‘ë‹µ ìƒì„±ì„ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œë“¤ì…ë‹ˆë‹¤.
í‚¤ì›Œë“œ ë§¤ì¹­ì—ì„œ ì§„ì •í•œ AI ê¸°ë°˜ ëŒ€í™” ì‹œìŠ¤í…œìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œë©ë‹ˆë‹¤.

SOLID ì›ì¹™ì„ ì¤€ìˆ˜í•˜ì—¬ ê° ë…¸ë“œê°€ ë‹¨ì¼ ì±…ì„ì„ ê°€ì§€ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import asyncio
import logging
import os
from typing import Dict, Any, Optional
import re

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.callbacks import BaseCallbackHandler

from ..models import ChatState, IntentType, ParsedIntent, MessageRole
from .state_utils import update_workflow_step, set_error, increment_step_count

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# LLM ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from .llm_utils import get_llm


async def llm_parse_intent(state: ChatState) -> ChatState:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤
    
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  MCP ë„êµ¬ì˜ ì„¤ëª…ì„ LLMì—ê²Œ ì œê³µí•˜ì—¬
    ì‚¬ìš©ì ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
    Returns:
        ì˜ë„ ë¶„ì„ì´ ì™„ë£Œëœ ìƒíƒœ
    """
    try:
        current_message = state.get("current_message")
        mcp_client = state.get("mcp_client")
        
        if not current_message:
            raise ValueError("í˜„ì¬ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ì‚¬ìš©ì ì…ë ¥ ì •ë¦¬
        user_input = current_message.content
        user_input_clean = re.sub(r'[\U00010000-\U0010ffff]|[\u2600-\u27BF]|[\uD800-\uDBFF][\uDC00-\uDFFF]', '', user_input)
        user_input_clean = user_input_clean.strip()
        
        logger.info(f"ë™ì  LLM ì˜ë„ ë¶„ì„ ì‹œì‘: {user_input_clean}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ìˆ˜ì§‘
        available_tools_info = ""
        if mcp_client:
            try:
                tools = mcp_client.get_tools()
                server_names = mcp_client.get_server_names()
                
                tool_descriptions = []
                for tool in tools:
                    tool_name = getattr(tool, 'name', 'ì´ë¦„ì—†ìŒ')
                    tool_desc = getattr(tool, 'description', 'ì„¤ëª…ì—†ìŒ')
                    
                    # ë„êµ¬ëª…ë§Œ ì‚¬ìš© (ì„œë²„ëª… ì œì™¸)
                    tool_descriptions.append(f"- {tool_name}: {tool_desc}")
                
                if tool_descriptions:
                    available_tools_info = "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:\n" + "\n".join(tool_descriptions)
                else:
                    available_tools_info = "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤."
                    
            except Exception as e:
                logger.warning(f"ë„êµ¬ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                available_tools_info = "ë„êµ¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            available_tools_info = "MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # LLMì„ ì‚¬ìš©í•œ ë™ì  ì˜ë„ ë¶„ì„
        llm = get_llm()
        
        # ë™ì  ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸ (ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ êµ¬ì„±)
        system_prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” AIì…ë‹ˆë‹¤.

{available_tools_info}

ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. TOOL_CALL: ìœ„ì˜ ë„êµ¬ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°
   - ë„êµ¬ ì´ë¦„ê³¼ í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •í™•íˆ ì‹ë³„í•´ì£¼ì„¸ìš”
   - ì—¬ëŸ¬ ë„êµ¬ê°€ í•„ìš”í•œ ê²½ìš° ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”

2. GENERAL_CHAT: ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ì •ë³´ ì œê³µ ìš”ì²­
   - ë„êµ¬ ì—†ì´ ë‹µë³€ ê°€ëŠ¥í•œ ê²½ìš°

3. HELP: ë„ì›€ë§ì´ë‚˜ ì‚¬ìš©ë²• ë¬¸ì˜
4. SERVER_STATUS: MCP ì„œë²„ ìƒíƒœ í™•ì¸  
5. TOOL_LIST: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ìš”ì²­

ì‘ë‹µ í˜•ì‹:
INTENT: [ì˜ë„]
CONFIDENCE: [0.0-1.0 ì‹ ë¢°ë„]
TARGET_TOOL: [ì •í™•í•œ ë„êµ¬ëª… ë˜ëŠ” null]
PARAMETERS: [ì¶”ì¶œëœ ë§¤ê°œë³€ìˆ˜ë“¤, JSON í˜•ì‹]
REASONING: [ì„ íƒ ê·¼ê±°]

ì¤‘ìš”: TARGET_TOOLì€ ìœ„ì— ë‚˜ì—´ëœ ë„êµ¬ëª…ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì˜ˆì‹œ:
INTENT: TOOL_CALL
CONFIDENCE: 0.95
TARGET_TOOL: get_weather
PARAMETERS: {{"location": "ë¶€ì‚°"}}
REASONING: ì‚¬ìš©ìê°€ ë¶€ì‚°ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.

ì¤‘ìš” ì§€ì¹¨:
- ì—¬ëŸ¬ ì§€ì—­ì´ë‚˜ í•­ëª©ì´ ì–¸ê¸‰ëœ ê²½ìš°, ReAct ëª¨ë“œë¥¼ ê¶Œì¥í•˜ì„¸ìš”
- ë³µì¡í•œ ë¹„êµë‚˜ ë¶„ì„ ìš”ì²­ì€ ReAct ëª¨ë“œì—ì„œ ì²˜ë¦¬í•˜ì„¸ìš”
- ë‹¨ìˆœí•œ ë‹¨ì¼ ì •ë³´ ì¡°íšŒë§Œ ì´ ëª¨ë“œì—ì„œ ì²˜ë¦¬í•˜ì„¸ìš”"""

        # ì•ˆì „í•œ ë©”ì‹œì§€ êµ¬ì„± (ChatPromptTemplate ì—†ì´)
        from langchain_core.messages import SystemMessage, HumanMessage
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_input_clean)
        ]
        
        # LLM í˜¸ì¶œ
        response = await llm.ainvoke(messages)
        response_text = response.content
        
        # ì‘ë‹µ íŒŒì‹± (ì›ë³¸ user_input ì‚¬ìš©)
        parsed_intent = _parse_llm_intent_response(response_text, user_input)
        state["parsed_intent"] = parsed_intent
        
        # ë³µì¡í•œ ìš”ì²­ ê°ì§€ (ReAct ëª¨ë“œ ì „í™˜ ì—¬ë¶€ ê²°ì •)
        user_input_clean = user_input.strip()
        user_input_lower = user_input_clean.lower()
        
        # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
        comma_count = len(re.findall(r'[,ï¼Œ]', user_input_clean))
        keyword_matches = [keyword for keyword in ['ë¹„êµ', 'ë¶„ì„', 'ë¦¬í¬íŠ¸', 'ì—¬ëŸ¬', 'ëª¨ë“ ', 'ê°ê°'] if keyword in user_input_lower]
        korean_word_groups = re.findall(r'[ê°€-í£]{2,}(?:\\s*,\\s*[ê°€-í£]{2,}){2,}', user_input_clean)
        
        logger.info(f"ë³µì¡í•œ ìš”ì²­ ê°ì§€ ë¶„ì„:")
        logger.info(f"  ì…ë ¥: '{user_input_clean}'")
        logger.info(f"  ì‰¼í‘œ ê°œìˆ˜: {comma_count}")
        logger.info(f"  í‚¤ì›Œë“œ ë§¤ì¹˜: {keyword_matches}")
        logger.info(f"  í•œêµ­ì–´ ë‹¨ì–´ ê·¸ë£¹: {korean_word_groups}")
        
        # ë” ì—„ê²©í•œ ë³µì¡í•œ ìš”ì²­ ê°ì§€ ì¡°ê±´
        is_complex_request = (
            comma_count >= 3 or  # ì‰¼í‘œê°€ 3ê°œ ì´ìƒ (ë” ì—„ê²©)
            (len(keyword_matches) > 0 and comma_count >= 1) or  # í‚¤ì›Œë“œê°€ ìˆê³  ì‰¼í‘œë„ ìˆëŠ” ê²½ìš°
            len(korean_word_groups) > 0  # 3ê°œ ì´ìƒì˜ í•œêµ­ì–´ ë‹¨ì–´ê°€ ì‰¼í‘œë¡œ êµ¬ë¶„
        )
        
        logger.info(f"  ë³µì¡í•œ ìš”ì²­ ì—¬ë¶€: {is_complex_request}")
        
        if is_complex_request and not state.get("react_mode"):
            logger.info(f"ë³µì¡í•œ ìš”ì²­ ê°ì§€ - ReAct ëª¨ë“œë¡œ ì „í™˜: {user_input_clean}")
            # ReAct ëª¨ë“œë¡œ ì „í™˜
            state["react_mode"] = True
            state["should_use_react"] = True
            update_workflow_step(state, "switch_to_react")
            return state
        
        # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
        if parsed_intent.is_mcp_action():
            update_workflow_step(state, "llm_call_mcp_tool")
        else:
            update_workflow_step(state, "llm_generate_response")
        
        logger.info(f"ë™ì  LLM ì˜ë„ ë¶„ì„ ì™„ë£Œ: {parsed_intent.intent_type.value}")
        if parsed_intent.target_server and parsed_intent.target_tool:
            logger.info(f"ì„ íƒëœ ë„êµ¬: {parsed_intent.target_server}.{parsed_intent.target_tool}")
        
        return state
        
    except Exception as e:
        logger.error(f"ë™ì  LLM ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ëŒ€í™”ë¡œ ì²˜ë¦¬
        from ..models import ParsedIntent, IntentType
        fallback_intent = ParsedIntent(
            intent_type=IntentType.GENERAL_CHAT,
            confidence=0.5,
            parameters={},
            target_server=None,
            target_tool=None
        )
        state["parsed_intent"] = fallback_intent
        update_workflow_step(state, "llm_generate_response")
        return state


async def llm_call_mcp_tool(state: ChatState) -> ChatState:
    """LLMì´ MCP ë„êµ¬ í˜¸ì¶œì„ ê²°ì •í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤
    
    ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ MCP ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ stateì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
    Returns:
        ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ê°€ í¬í•¨ëœ ìƒíƒœ
    """
    try:
        parsed_intent = state.get("parsed_intent")
        if not parsed_intent:
            raise ValueError("íŒŒì‹±ëœ ì˜ë„ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # MCP í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
        mcp_client = state.get("mcp_client")
        logger.info(f"LLM MCP ë„êµ¬ í˜¸ì¶œ ì‹œì‘:")
        logger.info(f"  ëŒ€ìƒ: {parsed_intent.target_server}.{parsed_intent.target_tool}")
        logger.info(f"  MCP í´ë¼ì´ì–¸íŠ¸ ì¡´ì¬: {mcp_client is not None}")
        if mcp_client:
            logger.info(f"  MCP í´ë¼ì´ì–¸íŠ¸ íƒ€ì…: {type(mcp_client)}")
            logger.info(f"  call_tool ë©”ì„œë“œ ì¡´ì¬: {hasattr(mcp_client, 'call_tool')}")
        
        # ë„êµ¬ í˜¸ì¶œ ì „ ìƒíƒœ í™•ì¸
        logger.info(f"ë„êµ¬ í˜¸ì¶œ ì „ tool_calls ê¸¸ì´: {len(state.get('tool_calls', []))}")
        
        # ê¸°ì¡´ ë„êµ¬ í˜¸ì¶œ ë¡œì§ ì¬ì‚¬ìš© (ë¹„ë™ê¸° í˜¸ì¶œ)
        from .nodes import call_mcp_tool
        updated_state = await call_mcp_tool(state)
        
        # ë„êµ¬ í˜¸ì¶œ í›„ ìƒíƒœ í™•ì¸
        tool_calls_after = updated_state.get("tool_calls", [])
        logger.info(f"ë„êµ¬ í˜¸ì¶œ í›„ tool_calls ê¸¸ì´: {len(tool_calls_after)}")
        if tool_calls_after:
            logger.info(f"ë§ˆì§€ë§‰ í˜¸ì¶œ ê²°ê³¼: {tool_calls_after[-1].server_name}.{tool_calls_after[-1].tool_name} = {tool_calls_after[-1].result}")
        
        # ë‹¤ìŒ ë‹¨ê³„ë¡œ LLM ì‘ë‹µ ìƒì„±
        update_workflow_step(updated_state, "llm_generate_response")
        return updated_state
        
    except Exception as e:
        logger.error(f"LLM MCP ë„êµ¬ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        logger.exception("LLM MCP ë„êµ¬ í˜¸ì¶œ ìƒì„¸ ì˜¤ë¥˜:")
        set_error(state, f"ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return state


def llm_generate_response(state: ChatState) -> ChatState:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤
    
    ì‚¬ìš©ì ì§ˆë¬¸ê³¼ MCP ë„êµ¬ ê²°ê³¼(ìˆëŠ” ê²½ìš°)ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ChatGPTê°€ ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
    Returns:
        LLM ì‘ë‹µì´ í¬í•¨ëœ ìƒíƒœ
    """
    try:
        current_message = state.get("current_message")
        parsed_intent = state.get("parsed_intent")
        # ì‹¤ì œ ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (tool_callsì—ì„œ)
        tool_calls = state.get("tool_calls", [])
        
        if not current_message:
            raise ValueError("í˜„ì¬ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        user_input = current_message.content
        logger.info(f"LLM ì‘ë‹µ ìƒì„± ì‹œì‘: {parsed_intent.intent_type.value if parsed_intent else 'None'}")
        
        # ì‹œìŠ¤í…œ ì •ë³´ ìš”ì²­ì¸ ê²½ìš° ì§ì ‘ ì •ë³´ ì œê³µ
        if parsed_intent and parsed_intent.intent_type == IntentType.TOOL_LIST:
            # MCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‹¤ì œ ë„êµ¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            mcp_client = state.get("mcp_client")
            if mcp_client:
                try:
                    server_names = mcp_client.get_server_names()
                    tools_info = mcp_client.get_tools_info()
                    
                    # ë™ì ìœ¼ë¡œ ë„êµ¬ ëª©ë¡ ìƒì„±
                    content_parts = ["## ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡\n", "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"]
                    
                    for server_name in server_names:
                        server_tools = tools_info.get(server_name, [])
                        if server_tools:
                            # ì„œë²„ë³„ ì„¹ì…˜ ì¶”ê°€ (ë™ì  ì•„ì´ì½˜ ìƒì„±)
                            server_icon = _get_server_icon(server_name)
                            content_parts.append(f"\n### {server_icon} {server_name} ì„œë²„")
                            
                            for tool in server_tools:
                                tool_name = tool.get('name', 'ì´ë¦„ì—†ìŒ')
                                tool_desc = tool.get('description', 'ì„¤ëª…ì—†ìŒ')
                                content_parts.append(f"- **{tool_name}**: {tool_desc}")
                    
                    # ì‚¬ìš©ë²• ì•ˆë‚´ ì¶”ê°€
                    content_parts.extend([
                        "\n### ğŸ“ ë„êµ¬ ì‚¬ìš© ì‹œ ìœ ì˜ì‚¬í•­",
                        "- ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” í•­ìƒ ì •í™•í•œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ìš”ì²­í•´ ì£¼ì„¸ìš”.",
                        "- ë„êµ¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ê²½ìš°, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆì§€ ê³ ë¯¼í•´ë³´ì„¸ìš”.",
                        "\nì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
                    ])
                    
                    system_info_content = "\n".join(content_parts)
                    
                except Exception as e:
                    logger.error(f"ë„êµ¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
                    system_info_content = "## ğŸ”§ ë„êµ¬ ëª©ë¡\n\në„êµ¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                # MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš°
                system_info_content = "## ğŸ”§ ë„êµ¬ ëª©ë¡\n\nMCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            state["response"] = system_info_content
            state["success"] = True
            update_workflow_step(state, "completed")
            return state
        
        elif parsed_intent and parsed_intent.intent_type == IntentType.SERVER_STATUS:
            # MCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‹¤ì œ ì„œë²„ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
            mcp_client = state.get("mcp_client")
            if mcp_client:
                try:
                    server_names = mcp_client.get_server_names()
                    server_count = mcp_client.get_server_count()
                    tool_count = len(mcp_client.get_tool_names())
                    
                    # ë™ì ìœ¼ë¡œ ì„œë²„ ìƒíƒœ ìƒì„±
                    content_parts = ["## ğŸŸ¢ ì„œë²„ ìƒíƒœ\n", "### ì—°ê²°ëœ ì„œë²„"]
                    
                    for server_name in server_names:
                        server_icon = _get_server_icon(server_name)
                        content_parts.append(f"- **{server_name}**: {server_icon} ì„œë²„ âœ…")
                    
                    content_parts.extend([
                        "\n### ì‹œìŠ¤í…œ ìƒíƒœ",
                        f"- **ì„œë²„**: {server_count}ê°œ í™œì„±í™”",
                        f"- **ë„êµ¬**: {tool_count}ê°œ ì‚¬ìš© ê°€ëŠ¥", 
                        "- **ìƒíƒœ**: ëª¨ë“  ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘",
                        "\nëª¨ë“  ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©° ë„êµ¬ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                    ])
                    
                    system_info_content = "\n".join(content_parts)
                    
                except Exception as e:
                    logger.error(f"ì„œë²„ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
                    system_info_content = "## ğŸŸ¢ ì„œë²„ ìƒíƒœ\n\nì„œë²„ ìƒíƒœ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                # MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš°
                system_info_content = "## ğŸŸ¢ ì„œë²„ ìƒíƒœ\n\nMCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            state["response"] = system_info_content
            state["success"] = True
            update_workflow_step(state, "completed")
            return state
        
        # ë””ë²„ê¹…: tool_calls ë‚´ìš© í™•ì¸
        logger.info(f"tool_calls ê¸¸ì´: {len(tool_calls)}")
        if tool_calls:
            for i, call in enumerate(tool_calls):
                logger.info(f"tool_call[{i}]: {call.server_name}.{call.tool_name} = {call.result}")
        else:
            logger.info("tool_callsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        
        llm = get_llm()
        
        # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_message = """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë§Œì•½ ì™¸ë¶€ ë„êµ¬(MCP ë„êµ¬)ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ ìˆë‹¤ë©´, ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´, ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ìµœì„ ì˜ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì‘ë‹µ í˜•ì‹**: 
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì ì ˆí•œ ì œëª©(##), ëª©ë¡(-), ê°•ì¡°(**í…ìŠ¤íŠ¸**), ì½”ë“œ(`ì½”ë“œ`) ë“±ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì •ë³´ê°€ ë§ì„ ë•ŒëŠ” êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

        messages = [SystemMessage(content=system_message)]
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_input = state.get("current_message", BaseMessage(content="", type="human")).content
        
        # ê¸°ë³¸ ì‚¬ìš©ì ì»¨í…ì¸  ì´ˆê¸°í™”
        user_content = f"ì‚¬ìš©ì ì§ˆë¬¸: {user_input}"
        
        # MCP ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì¶”ê°€
        if tool_calls:
            user_content += "\n\në„êµ¬ ì‹¤í–‰ ê²°ê³¼:"
            for i, mcp_call in enumerate(tool_calls):
                if mcp_call.is_successful():
                    user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: {mcp_call.result}"
                else:
                    user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: ì˜¤ë¥˜ - {mcp_call.error}"
            
            # ë„êµ¬ í˜¸ì¶œ ì •ë³´ ìš”ì•½ ì¶”ê°€
            user_content += "\n\nì‚¬ìš©ëœ ë„êµ¬:"
            for mcp_call in tool_calls:
                user_content += f"\n- {mcp_call.server_name}.{mcp_call.tool_name}({mcp_call.arguments})"
        
        messages.append(HumanMessage(content=user_content))
        
        # ë””ë²„ê¹…: LLMì— ì „ë‹¬ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ë‚´ìš© ì¶œë ¥
        logger.info(f"LLMì— ì „ë‹¬ë˜ëŠ” í”„ë¡¬í”„íŠ¸:")
        logger.info(f"ì‹œìŠ¤í…œ ë©”ì‹œì§€: {system_message}")
        logger.info(f"ì‚¬ìš©ì ì»¨í…ì¸ : {user_content}")
        
        # LLM ì‘ë‹µ ìƒì„±
        response = llm.invoke(messages)
        generated_response = response.content
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["response"] = generated_response
        state["success"] = True
        update_workflow_step(state, "completed")
        
        logger.info("LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        return state
        
    except Exception as e:
        logger.error(f"LLM ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        logger.info("ê¸°ì¡´ ë°©ì‹ ì‘ë‹µ ìƒì„±ìœ¼ë¡œ í´ë°±")
        update_workflow_step(state, "generate_response")
        return state


def _parse_llm_intent_response(response_text: str, user_input: str) -> ParsedIntent:
    """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ParsedIntent ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤
    
    Args:
        response_text: LLMì˜ ì›ì‹œ ì‘ë‹µ í…ìŠ¤íŠ¸
        user_input: ì›ë³¸ ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        íŒŒì‹±ëœ ì˜ë„ ê°ì²´
    """
    try:
        lines = response_text.strip().split('\n')
        intent_type_str = "GENERAL_CHAT"
        confidence = 0.5
        parameters = {}
        target_server = None
        target_tool = None
        
        for line in lines:
            line = line.strip()
            if line.startswith("INTENT:"):
                intent_type_str = line.replace("INTENT:", "").strip()
            elif line.startswith("CONFIDENCE:"):
                try:
                    confidence = float(line.replace("CONFIDENCE:", "").strip())
                except ValueError:
                    confidence = 0.5
            elif line.startswith("TARGET_TOOL:"):
                tool_str = line.replace("TARGET_TOOL:", "").strip()
                target_tool = tool_str if tool_str.lower() != "null" else None
            elif line.startswith("PARAMETERS:"):
                param_str = line.replace("PARAMETERS:", "").strip()
                try:
                    import json
                    parameters = json.loads(param_str)
                except (json.JSONDecodeError, ValueError):
                    parameters = {}
        
        # IntentTypeìœ¼ë¡œ ë³€í™˜
        try:
            intent_type = IntentType(intent_type_str)
        except ValueError:
            intent_type = IntentType.GENERAL_CHAT
        
        # ë„êµ¬ëª…ìœ¼ë¡œ ì„œë²„ ìë™ ì¶”ë¡  (ë™ì  ë°©ì‹)
        if target_tool:
            target_server = _infer_server_from_tool(target_tool)
        
        # TOOL_CALLì¸ë° target_toolì´ ì—†ìœ¼ë©´ í´ë°±
        if intent_type == IntentType.TOOL_CALL and not target_tool:
            # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            target_server, target_tool = _determine_target_from_intent_fallback(parameters, user_input)
        
        return ParsedIntent(
            intent_type=intent_type,
            confidence=confidence,
            parameters=parameters,
            target_server=target_server,
            target_tool=target_tool
        )
        
    except Exception as e:
        logger.warning(f"LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return ParsedIntent(
            intent_type=IntentType.GENERAL_CHAT,
            confidence=0.3,
            parameters={},
            target_server=None,
            target_tool=None
        )


def _infer_server_from_tool(tool_name: str) -> Optional[str]:
    """ë„êµ¬ëª…ìœ¼ë¡œë¶€í„° ì„œë²„ëª…ì„ ë™ì ìœ¼ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤ (ì™„ì „ ë™ì  ë°©ì‹)"""
    if not tool_name:
        return None
    
    # ë„êµ¬ëª…ì—ì„œ ì„œë²„ëª… ì¶”ì¶œ ì‹œë„
    tool_lower = tool_name.lower()
    
    # í•˜ì´í”ˆì´ë‚˜ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ êµ¬ë¶„ëœ ê²½ìš° ì²« ë²ˆì§¸ ë¶€ë¶„ì„ ì„œë²„ë¡œ ì¶”ì •
    if '-' in tool_name:
        potential_server = tool_name.split('-')[0]
        return potential_server
    elif '_' in tool_name:
        potential_server = tool_name.split('_')[0]
        return potential_server
    
    # ê¸°ë³¸ê°’: None (MCP í´ë¼ì´ì–¸íŠ¸ê°€ ìë™ìœ¼ë¡œ ì°¾ë„ë¡)
    return None


def _determine_target_from_intent_fallback(parameters: Dict[str, Any], user_input: str) -> tuple[Optional[str], Optional[str]]:
    """í´ë°±: ë§¤ê°œë³€ìˆ˜ì™€ ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œë¶€í„° ëŒ€ìƒ ì„œë²„ì™€ ë„êµ¬ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤ (ì™„ì „ ë™ì  ë°©ì‹)"""
    # í•˜ë“œì½”ë”©ëœ í‚¤ì›Œë“œ ë§¤ì¹­ ì œê±°
    # ë§¤ê°œë³€ìˆ˜ë‚˜ ì‚¬ìš©ì ì…ë ¥ì—ì„œ íŒíŠ¸ë¥¼ ì°¾ë˜, íŠ¹ì • ë„êµ¬ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ
    
    # ë§¤ê°œë³€ìˆ˜ì—ì„œ íŒíŠ¸ ì°¾ê¸°
    if parameters:
        # ì²« ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ í‚¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ 
        first_key = list(parameters.keys())[0] if parameters else None
        first_value = list(parameters.values())[0] if parameters else None
        
        if first_key and first_value:
            # ë§¤ê°œë³€ìˆ˜ ì´ë¦„ê³¼ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì¼ë°˜ì ì¸ ì¶”ë¡ 
            return None, None  # ë™ì  ì‹œìŠ¤í…œì—ì„œëŠ” LLMì´ ê²°ì •í•˜ë„ë¡ í•¨
    
    # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì„œë²„ë‚˜ ë„êµ¬ ì´ë¦„ì´ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ê²½ìš°ë§Œ ì²˜ë¦¬
    user_lower = user_input.lower()
    
    # ëª…ì‹œì ì¸ ì„œë²„/ë„êµ¬ ì–¸ê¸‰ ì°¾ê¸° (ë™ì )
    import re
    
    # "ì„œë²„ëª….ë„êµ¬ëª…" íŒ¨í„´ ì°¾ê¸°
    server_tool_pattern = r'(\w+)\.(\w+)'
    matches = re.findall(server_tool_pattern, user_input)
    if matches:
        return matches[0][0], matches[0][1]
    
    # íŠ¹ì • ì„œë²„ê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ê²½ìš°
    server_mentions = re.findall(r'(\w+)\s*(?:ì„œë²„|server)', user_lower)
    if server_mentions:
        return server_mentions[0], None
    
    # ê¸°ë³¸ì ìœ¼ë¡œëŠ” LLMì´ ê²°ì •í•˜ë„ë¡ None ë°˜í™˜
    return None, None


class StreamingCallbackHandler(BaseCallbackHandler):
    """í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""
    
    def __init__(self, sse_manager, session_id: str):
        self.sse_manager = sse_manager
        self.session_id = session_id
        self.current_content = ""
        self.token_count = 0
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """ìƒˆ í† í°ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ í˜¸ì¶œ"""
        if token and token.strip():  # ê³µë°± í† í° ë¬´ì‹œ
            self.current_content += token
            self.token_count += 1
            
            # ë™ì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
            batch_size = max(2, min(5, 3 + (self.token_count // 20)))  # 2-5 ì‚¬ì´ì—ì„œ ì ì‘ì  ì¡°ì •
            
            # ë™ì  ë°°ì¹˜ë§ˆë‹¤ ì „ì†¡
            if self.token_count % batch_size == 0:
                self._send_partial_update_sync()
    
    def on_llm_end(self, response, **kwargs) -> None:
        """LLM ì‘ë‹µ ì™„ë£Œ ì‹œ ë§ˆì§€ë§‰ í† í°ë“¤ ì „ì†¡"""
        if self.current_content:
            self._send_partial_update_sync()
    
    def _send_partial_update_sync(self):
        """ë¶€ë¶„ ì—…ë°ì´íŠ¸ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì „ì†¡"""
        try:
            from ..streaming import create_partial_response_message
            
            partial_msg = create_partial_response_message(
                self.current_content,
                self.session_id
            )
            
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì „ì†¡
            import asyncio
            import threading
            
            def send_message():
                try:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    loop.run_until_complete(
                        self.sse_manager.send_to_session(self.session_id, partial_msg)
                    )
                    loop.close()
                except Exception as e:
                    import logging
                    logger = logging.getLogger(__name__)
                    logger.warning(f"ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            thread = threading.Thread(target=send_message, daemon=True)
            thread.start()
            
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.warning(f"ë¶€ë¶„ ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨: {e}")


async def llm_generate_response_with_streaming(state: ChatState, sse_manager, session_id: str) -> ChatState:
    """í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ê³¼ í•¨ê»˜ LLM ì‘ë‹µ ìƒì„± (ìµœì í™”ëœ ë²„ì „)"""
    try:
        increment_step_count(state)
        logger.info("LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹œì‘ (ìµœì í™”ëœ ë²„ì „)")
        
        user_input = state.get("current_message", BaseMessage(content="", type="human")).content
        tool_calls = state.get("tool_calls", [])
        parsed_intent = state.get("parsed_intent")
        
        logger.info(f"ì‚¬ìš©ì ì…ë ¥: {user_input}")
        logger.info(f"íŒŒì‹±ëœ ì˜ë„: {parsed_intent.intent_type if parsed_intent else 'None'}")
        logger.info(f"ë„êµ¬ í˜¸ì¶œ ìˆ˜: {len(tool_calls)}")
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì‘ë‹µ ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        if parsed_intent and parsed_intent.intent_type in [IntentType.TOOL_LIST, IntentType.SERVER_STATUS]:
            logger.info("ì‹œìŠ¤í…œ ì •ë³´ ì‘ë‹µìœ¼ë¡œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            return llm_generate_response(state)  # ì‹œìŠ¤í…œ ì •ë³´ëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        
        logger.info("ìµœì í™”ëœ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì§„í–‰")
        
        # LLM ì‚¬ìš©
        llm = get_llm()
        
        # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
        system_message = """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ì˜ ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ í†µí•´ ë§¥ë½ì„ ì´í•´í•˜ê³  ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ëŒ€í™” ë§¥ë½ í™œìš©**:
- ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ "ê·¸ê²ƒ", "ê·¸ê±°", "ìœ„ì—ì„œ ë§í•œ" ë“±ìœ¼ë¡œ ì´ì „ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ë©´ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”
- ì—°ê´€ëœ ì£¼ì œë‚˜ í›„ì† ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë§¥ë½ì„ ìœ ì§€í•˜ì„¸ìš”

**ë„êµ¬ ê²°ê³¼ í™œìš©**:
- ì™¸ë¶€ ë„êµ¬(MCP ë„êµ¬) ê²°ê³¼ê°€ ìˆë‹¤ë©´, ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”
- ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´, ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ìµœì„ ì˜ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”

**ì‘ë‹µ í˜•ì‹**: 
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì ì ˆí•œ ì œëª©(##), ëª©ë¡(-), ê°•ì¡°(**í…ìŠ¤íŠ¸**), ì½”ë“œ(`ì½”ë“œ`) ë“±ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì •ë³´ê°€ ë§ì„ ë•ŒëŠ” êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

        messages = [SystemMessage(content=system_message)]
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì¶”ê°€
        conversation_history = state.get("messages", [])
        logger.info(f"ëŒ€í™” íˆìŠ¤í† ë¦¬: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
        
        if len(conversation_history) > 1:  # í˜„ì¬ ë©”ì‹œì§€ ì™¸ì— ì´ì „ ë©”ì‹œì§€ê°€ ìˆëŠ” ê²½ìš°
            logger.info("ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨")
            
            # ì´ì „ ë©”ì‹œì§€ë“¤ (í˜„ì¬ ë©”ì‹œì§€ ì œì™¸)ì„ LLM ë©”ì‹œì§€ë¡œ ë³€í™˜
            for msg in conversation_history[:-1]:  # ë§ˆì§€ë§‰ ë©”ì‹œì§€(í˜„ì¬ ë©”ì‹œì§€) ì œì™¸
                if msg.role == MessageRole.USER:
                    messages.append(HumanMessage(content=msg.content))
                elif msg.role == MessageRole.ASSISTANT:
                    messages.append(AIMessage(content=msg.content))
                # TOOL ë©”ì‹œì§€ëŠ” ìŠ¤í‚µ (LLM ë©”ì‹œì§€ íƒ€ì…ì— ì—†ìŒ)
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ë° ë„êµ¬ ê²°ê³¼ ì¶”ê°€
        current_user_content = f"ì‚¬ìš©ì ì§ˆë¬¸: {user_input}"
        
        # MCP ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì¶”ê°€
        if tool_calls:
            current_user_content += "\n\në°©ê¸ˆ ì‹¤í–‰ëœ ë„êµ¬ ê²°ê³¼:"
            for i, mcp_call in enumerate(tool_calls):
                if mcp_call.is_successful():
                    current_user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: {mcp_call.result}"
                else:
                    current_user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: ì˜¤ë¥˜ - {mcp_call.error}"
            
            # ë„êµ¬ í˜¸ì¶œ ì •ë³´ ìš”ì•½ ì¶”ê°€
            current_user_content += "\n\nì‚¬ìš©ëœ ë„êµ¬:"
            for mcp_call in tool_calls:
                current_user_content += f"\n- {mcp_call.server_name}.{mcp_call.tool_name}({mcp_call.arguments})"
        
        messages.append(HumanMessage(content=current_user_content))
        
        logger.info(f"LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ ìˆ˜: {len(messages)} (ì‹œìŠ¤í…œ: 1, íˆìŠ¤í† ë¦¬: {len(conversation_history)-1}, í˜„ì¬: 1)")
        
        # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (ë‹¨ì–´ ë‹¨ìœ„ ë°©ì‹)
        logger.info("ë‹¨ì–´ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...")
        
        full_response = ""
        word_buffer = ""  # ë‹¨ì–´ ë²„í¼ë¡œ ë³€ê²½
        token_count = 0
        
        try:
            # LLM ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
            async for chunk in llm.astream(messages):
                if hasattr(chunk, 'content') and chunk.content:
                    token = chunk.content
                    full_response += token
                    word_buffer += token
                    token_count += 1
                    
                    # ë‹¨ì–´ ë‹¨ìœ„ ë²„í¼ë§ ì „ëµ (ë™ì  ë°©ì‹)
                    max_word_length = 12 + len(token) // 2  # í† í° ê¸¸ì´ì— ë”°ë¥¸ ì ì‘ì  ë²„í¼
                    token_batch_size = 15 + (token_count // 10)  # ì§„í–‰ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ì¦ê°€
                    
                    should_send = (
                        token in [' ', '\t'] or  # ê³µë°±ì´ë‚˜ íƒ­ (ë‹¨ì–´ êµ¬ë¶„ì)
                        token in ['.', '!', '?', ',', ';', ':', '\n'] or  # êµ¬ë‘ì ì´ë‚˜ ì¤„ë°”ê¿ˆ
                        token in ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼Œ', 'ï¼›', 'ï¼š'] or  # í•œêµ­ì–´/ì¤‘êµ­ì–´ êµ¬ë‘ì 
                        len(word_buffer) >= max_word_length or  # ì ì‘ì  ë‹¨ì–´ ê¸¸ì´ ì œí•œ
                        token_count % token_batch_size == 0  # ì ì‘ì  ë°°ì¹˜ ì „ì†¡
                    )
                    
                    if should_send and word_buffer.strip():  # ê³µë°±ë§Œ ìˆëŠ” ë²„í¼ëŠ” ì „ì†¡í•˜ì§€ ì•ŠìŒ
                        # ì™„ì „í•œ ë‹¨ì–´ ì „ì†¡
                        from ..streaming import create_partial_response_message
                        partial_msg = create_partial_response_message(word_buffer, session_id)
                        partial_msg.metadata = {"word_streaming": True, "cumulative": False}
                        
                        try:
                            await sse_manager.send_to_session(session_id, partial_msg)
                            logger.debug(f"ë‹¨ì–´ ì „ì†¡: '{word_buffer.strip()}' ({len(word_buffer)}ê¸€ì)")
                        except Exception as e:
                            logger.error(f"ë‹¨ì–´ ì „ì†¡ ì‹¤íŒ¨: {e}")
                        
                        # ë²„í¼ ì´ˆê¸°í™”
                        word_buffer = ""
                        
                        # ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° ì§€ì—° (ë™ì  ê³„ì‚°)
                        base_delay = 0.03  # ê¸°ë³¸ ì§€ì—°
                        if token in ['.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ']:
                            delay = base_delay * 5  # ë¬¸ì¥ ë
                        elif token in [',', ';', 'ï¼Œ', 'ï¼›']:
                            delay = base_delay * 2.5  # ì‰¼í‘œ
                        elif token == '\n':
                            delay = base_delay * 3  # ì¤„ë°”ê¿ˆ
                        else:
                            delay = base_delay  # ì¼ë°˜ ë‹¨ì–´
                        
                        await asyncio.sleep(delay)
            
            # ë§ˆì§€ë§‰ ë‚¨ì€ ë‹¨ì–´ ì „ì†¡
            if word_buffer.strip():
                from ..streaming import create_partial_response_message
                partial_msg = create_partial_response_message(word_buffer, session_id)
                partial_msg.metadata = {"word_streaming": True, "cumulative": False, "final_word": True}
                await sse_manager.send_to_session(session_id, partial_msg)
                logger.debug(f"ë§ˆì§€ë§‰ ë‹¨ì–´ ì „ì†¡: '{word_buffer.strip()}'")
            
        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ì „ì²´ ì‘ë‹µì„ í•œ ë²ˆì— ìƒì„±
            response = await llm.ainvoke(messages)
            full_response = response.content
        
        logger.info(f"ë‹¨ì–´ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ - ì´ ê¸¸ì´: {len(full_response)}ê¸€ì, í† í° ìˆ˜: {token_count}")
        
        # ìµœì¢… ì‘ë‹µìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
        state["response"] = full_response
        state["success"] = True
        update_workflow_step(state, "completed")
        
        # ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥ (ì¤‘ìš”!)
        from .state import add_assistant_message
        add_assistant_message(state, full_response)
        
        # ìµœì¢… ì‘ë‹µ ë©”ì‹œì§€ ì „ì†¡ (ì „ì²´ í…ìŠ¤íŠ¸)
        logger.info("final_response ì „ì†¡ ì¤‘...")
        from ..streaming import create_final_response_message
        final_msg = create_final_response_message(full_response, session_id)
        try:
            await sse_manager.send_to_session(session_id, final_msg)
            logger.info("final_response ì „ì†¡ ì„±ê³µ")
        except Exception as e:
            logger.error(f"final_response ì „ì†¡ ì‹¤íŒ¨: {e}")
        
        logger.info("ìµœì í™”ëœ LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        return state
        
    except Exception as e:
        logger.error(f"LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        return llm_generate_response(state) 


def _get_server_icon(server_name: str) -> str:
    """ì„œë²„ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ë™ì ìœ¼ë¡œ ì•„ì´ì½˜ì„ ìƒì„±í•©ë‹ˆë‹¤"""
    server_lower = server_name.lower()
    
    # ì„œë²„ ì´ë¦„ì˜ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ì•„ì´ì½˜ ì„ íƒ
    if any(keyword in server_lower for keyword in ['weather', 'clima', 'forecast']):
        return "ğŸŒ¤ï¸"
    elif any(keyword in server_lower for keyword in ['file', 'files', 'manager', 'storage']):
        return "ğŸ“"
    elif any(keyword in server_lower for keyword in ['context', 'search', 'library', 'docs']):
        return "ğŸ“š"
    elif any(keyword in server_lower for keyword in ['web', 'http', 'api']):
        return "ğŸŒ"
    elif any(keyword in server_lower for keyword in ['database', 'db', 'sql']):
        return "ğŸ—„ï¸"
    elif any(keyword in server_lower for keyword in ['chat', 'message', 'communication']):
        return "ğŸ’¬"
    elif any(keyword in server_lower for keyword in ['time', 'clock', 'schedule']):
        return "â°"
    elif any(keyword in server_lower for keyword in ['security', 'auth', 'login']):
        return "ğŸ”"
    elif any(keyword in server_lower for keyword in ['image', 'photo', 'picture']):
        return "ğŸ–¼ï¸"
    elif any(keyword in server_lower for keyword in ['video', 'media', 'stream']):
        return "ğŸ¥"
    else:
        # ê¸°ë³¸ ë„êµ¬ ì•„ì´ì½˜
        return "ğŸ”§" 