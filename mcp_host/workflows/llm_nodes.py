"""LLM ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ë…¸ë“œ

OpenAI ChatGPTë¥¼ í™œìš©í•˜ì—¬ ìì—°ì–´ ì´í•´ì™€ ì‘ë‹µ ìƒì„±ì„ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œë“¤ì…ë‹ˆë‹¤.
í‚¤ì›Œë“œ ë§¤ì¹­ì—ì„œ ì§„ì •í•œ AI ê¸°ë°˜ ëŒ€í™” ì‹œìŠ¤í…œìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œë©ë‹ˆë‹¤.

SOLID ì›ì¹™ì„ ì¤€ìˆ˜í•˜ì—¬ ê° ë…¸ë“œê°€ ë‹¨ì¼ ì±…ì„ì„ ê°€ì§€ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import asyncio
import logging
import os
from typing import Dict, Any, Optional
import re

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.callbacks import BaseCallbackHandler

from ..models import ChatState, IntentType, ParsedIntent, MessageRole
from .state_utils import update_workflow_step, set_error, increment_step_count

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# LLM ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_llm_instance = None


def get_llm() -> ChatOpenAI:
    """ChatOpenAI LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
    
    í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì™€ LLMì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Returns:
        ChatOpenAI: ì„¤ì •ëœ OpenAI ì±„íŒ… ëª¨ë¸
        
    Raises:
        ValueError: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
    """
    global _llm_instance
    
    if _llm_instance is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError(
                "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )
        
        _llm_instance = ChatOpenAI(
            model="gpt-4o-mini",  # ë¹ ë¥´ê³  ê²½ì œì ì¸ ëª¨ë¸
            temperature=0.1,      # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
            max_tokens=1000,      # ì ì ˆí•œ ì‘ë‹µ ê¸¸ì´
        )
        logger.info("OpenAI ChatGPT ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return _llm_instance


def llm_parse_intent(state: ChatState) -> ChatState:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤
    
    ê¸°ì¡´ì˜ í‚¤ì›Œë“œ ë§¤ì¹­ ëŒ€ì‹  ChatGPTê°€ ìì—°ì–´ë¡œ ì‚¬ìš©ì ì˜ë„ë¥¼ ì´í•´í•©ë‹ˆë‹¤.
    ë” ì •í™•í•˜ê³  ìœ ì—°í•œ ì˜ë„ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
    Returns:
        ì˜ë„ ë¶„ì„ì´ ì™„ë£Œëœ ìƒíƒœ
    """
    try:
        current_message = state.get("current_message")
        if not current_message:
            raise ValueError("í˜„ì¬ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì´ëª¨ì§€ ì œê±° (UTF-8 ì¸ì½”ë”© ì—ëŸ¬ ë°©ì§€)
        user_input = current_message.content
        # ì´ëª¨ì§€ ì œê±° ì •ê·œì‹
        user_input_clean = re.sub(r'[\U00010000-\U0010ffff]|[\u2600-\u27BF]|[\uD800-\uDBFF][\uDC00-\uDFFF]', '', user_input)
        user_input_clean = user_input_clean.strip()
        
        logger.info(f"LLM ì˜ë„ ë¶„ì„ ì‹œì‘: {user_input_clean}")
        
        # LLMì„ ì‚¬ìš©í•œ ì˜ë„ ë¶„ì„
        llm = get_llm()
        
        # ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸
        intent_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì˜ë„ë¥¼ íŒŒì•…í•˜ëŠ” AIì…ë‹ˆë‹¤.
ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ì˜ë„ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. WEATHER_QUERY: ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ (í˜„ì¬ ë‚ ì”¨, ì˜ˆë³´ ë“±)
2. FILE_OPERATION: íŒŒì¼/ë””ë ‰í† ë¦¬ ì‘ì—… (ëª©ë¡ ë³´ê¸°, íŒŒì¼ ì½ê¸° ë“±)  
3. SERVER_STATUS: MCP ì„œë²„ ìƒíƒœ í™•ì¸
4. TOOL_LIST: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ìš”ì²­
5. HELP: ë„ì›€ë§ì´ë‚˜ ì‚¬ìš©ë²• ë¬¸ì˜
6. GENERAL_CHAT: ì¼ë°˜ì ì¸ ëŒ€í™”

ì‘ë‹µ í˜•ì‹:
INTENT: [ì˜ë„]
CONFIDENCE: [0.0-1.0 ì‹ ë¢°ë„]
PARAMETERS: [ì¶”ì¶œëœ ë§¤ê°œë³€ìˆ˜ë“¤, JSON í˜•ì‹]
REASONING: [ë¶„ë¥˜ ê·¼ê±°]

ì˜ˆì‹œ:
INTENT: WEATHER_QUERY
CONFIDENCE: 0.95
PARAMETERS: {{"location": "ì„œìš¸", "forecast": true, "days": 3}}
REASONING: ì‚¬ìš©ìê°€ ì„œìš¸ì˜ 3ì¼ ì˜ˆë³´ë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤."""),
            ("human", "{user_input}")
        ])
        
        # LLM í˜¸ì¶œ
        chain = intent_prompt | llm
        response = chain.invoke({"user_input": user_input_clean})
        response_text = response.content
        
        # ì‘ë‹µ íŒŒì‹± (ì›ë³¸ user_input ì‚¬ìš©)
        parsed_intent = _parse_llm_intent_response(response_text, user_input)
        state["parsed_intent"] = parsed_intent
        
        # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
        if parsed_intent.is_mcp_action():
            update_workflow_step(state, "llm_call_mcp_tool")
        else:
            update_workflow_step(state, "llm_generate_response")
        
        logger.info(f"LLM ì˜ë„ ë¶„ì„ ì™„ë£Œ: {parsed_intent.intent_type.value}")
        return state
        
    except Exception as e:
        logger.error(f"LLM ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ í‚¤ì›Œë“œ ë°©ì‹ìœ¼ë¡œ í´ë°±
        logger.info("í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ì„ìœ¼ë¡œ í´ë°±")
        update_workflow_step(state, "parse_message")
        return state


async def llm_call_mcp_tool(state: ChatState) -> ChatState:
    """LLMì´ MCP ë„êµ¬ í˜¸ì¶œì„ ê²°ì •í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤
    
    ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ MCP ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ stateì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
    Returns:
        ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ê°€ í¬í•¨ëœ ìƒíƒœ
    """
    try:
        parsed_intent = state.get("parsed_intent")
        if not parsed_intent:
            raise ValueError("íŒŒì‹±ëœ ì˜ë„ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        logger.info(f"LLM MCP ë„êµ¬ í˜¸ì¶œ: {parsed_intent.target_server}.{parsed_intent.target_tool}")
        
        # ë„êµ¬ í˜¸ì¶œ ì „ ìƒíƒœ í™•ì¸
        logger.info(f"ë„êµ¬ í˜¸ì¶œ ì „ tool_calls ê¸¸ì´: {len(state.get('tool_calls', []))}")
        
        # ê¸°ì¡´ ë„êµ¬ í˜¸ì¶œ ë¡œì§ ì¬ì‚¬ìš© (ë¹„ë™ê¸° í˜¸ì¶œ)
        from .nodes import call_mcp_tool
        updated_state = await call_mcp_tool(state)
        
        # ë„êµ¬ í˜¸ì¶œ í›„ ìƒíƒœ í™•ì¸
        tool_calls_after = updated_state.get("tool_calls", [])
        logger.info(f"ë„êµ¬ í˜¸ì¶œ í›„ tool_calls ê¸¸ì´: {len(tool_calls_after)}")
        if tool_calls_after:
            logger.info(f"ë§ˆì§€ë§‰ í˜¸ì¶œ ê²°ê³¼: {tool_calls_after[-1].server_name}.{tool_calls_after[-1].tool_name} = {tool_calls_after[-1].result}")
        
        # ë‹¤ìŒ ë‹¨ê³„ë¡œ LLM ì‘ë‹µ ìƒì„±
        update_workflow_step(updated_state, "llm_generate_response")
        return updated_state
        
    except Exception as e:
        logger.error(f"LLM MCP ë„êµ¬ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        set_error(state, f"ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return state


def llm_generate_response(state: ChatState) -> ChatState:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤
    
    ì‚¬ìš©ì ì§ˆë¬¸ê³¼ MCP ë„êµ¬ ê²°ê³¼(ìˆëŠ” ê²½ìš°)ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ChatGPTê°€ ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
    Returns:
        LLM ì‘ë‹µì´ í¬í•¨ëœ ìƒíƒœ
    """
    try:
        current_message = state.get("current_message")
        parsed_intent = state.get("parsed_intent")
        # ì‹¤ì œ ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (tool_callsì—ì„œ)
        tool_calls = state.get("tool_calls", [])
        
        if not current_message:
            raise ValueError("í˜„ì¬ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        user_input = current_message.content
        logger.info(f"LLM ì‘ë‹µ ìƒì„± ì‹œì‘: {parsed_intent.intent_type.value if parsed_intent else 'None'}")
        
        # ì‹œìŠ¤í…œ ì •ë³´ ìš”ì²­ì¸ ê²½ìš° ì§ì ‘ ì •ë³´ ì œê³µ
        if parsed_intent and parsed_intent.intent_type == IntentType.TOOL_LIST:
            # MCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‹¤ì œ ë„êµ¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            mcp_client = state.get("mcp_client")
            if mcp_client:
                try:
                    server_names = mcp_client.get_server_names()
                    tools_info = mcp_client.get_tools_info()
                    
                    # ë™ì ìœ¼ë¡œ ë„êµ¬ ëª©ë¡ ìƒì„±
                    content_parts = ["## ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡\n", "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"]
                    
                    for server_name in server_names:
                        server_tools = tools_info.get(server_name, [])
                        if server_tools:
                            # ì„œë²„ë³„ ì„¹ì…˜ ì¶”ê°€
                            server_icon = "ğŸŒ¤ï¸" if server_name == "weather" else "ğŸ“" if server_name == "file-manager" else "ğŸ”§"
                            content_parts.append(f"\n### {server_icon} {server_name} ì„œë²„")
                            
                            for tool in server_tools:
                                tool_name = tool.get('name', 'ì´ë¦„ì—†ìŒ')
                                tool_desc = tool.get('description', 'ì„¤ëª…ì—†ìŒ')
                                content_parts.append(f"- **{tool_name}**: {tool_desc}")
                    
                    # ì‚¬ìš©ë²• ì•ˆë‚´ ì¶”ê°€
                    content_parts.extend([
                        "\n### ğŸ“ ë„êµ¬ ì‚¬ìš© ì‹œ ìœ ì˜ì‚¬í•­",
                        "- ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” í•­ìƒ ì •í™•í•œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ìš”ì²­í•´ ì£¼ì„¸ìš”.",
                        "- ë„êµ¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ê²½ìš°, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆì§€ ê³ ë¯¼í•´ë³´ì„¸ìš”.",
                        "\nì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
                    ])
                    
                    system_info_content = "\n".join(content_parts)
                    
                except Exception as e:
                    logger.error(f"ë„êµ¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
                    system_info_content = "## ğŸ”§ ë„êµ¬ ëª©ë¡\n\në„êµ¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                # MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš°
                system_info_content = "## ğŸ”§ ë„êµ¬ ëª©ë¡\n\nMCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            state["response"] = system_info_content
            state["success"] = True
            update_workflow_step(state, "completed")
            return state
        
        elif parsed_intent and parsed_intent.intent_type == IntentType.SERVER_STATUS:
            # MCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‹¤ì œ ì„œë²„ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
            mcp_client = state.get("mcp_client")
            if mcp_client:
                try:
                    server_names = mcp_client.get_server_names()
                    server_count = mcp_client.get_server_count()
                    tool_count = len(mcp_client.get_tool_names())
                    
                    # ë™ì ìœ¼ë¡œ ì„œë²„ ìƒíƒœ ìƒì„±
                    content_parts = ["## ğŸŸ¢ ì„œë²„ ìƒíƒœ\n", "### ì—°ê²°ëœ ì„œë²„"]
                    
                    for server_name in server_names:
                        server_icon = "ğŸŒ¤ï¸" if server_name == "weather" else "ğŸ“" if server_name == "file-manager" else "ğŸ”§"
                        content_parts.append(f"- **{server_name}**: {server_icon} ì„œë²„ âœ…")
                    
                    content_parts.extend([
                        "\n### ì‹œìŠ¤í…œ ìƒíƒœ",
                        f"- **ì„œë²„**: {server_count}ê°œ í™œì„±í™”",
                        f"- **ë„êµ¬**: {tool_count}ê°œ ì‚¬ìš© ê°€ëŠ¥", 
                        "- **ìƒíƒœ**: ëª¨ë“  ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘",
                        "\nëª¨ë“  ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©° ë„êµ¬ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                    ])
                    
                    system_info_content = "\n".join(content_parts)
                    
                except Exception as e:
                    logger.error(f"ì„œë²„ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
                    system_info_content = "## ğŸŸ¢ ì„œë²„ ìƒíƒœ\n\nì„œë²„ ìƒíƒœ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                # MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš°
                system_info_content = "## ğŸŸ¢ ì„œë²„ ìƒíƒœ\n\nMCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            state["response"] = system_info_content
            state["success"] = True
            update_workflow_step(state, "completed")
            return state
        
        # ë””ë²„ê¹…: tool_calls ë‚´ìš© í™•ì¸
        logger.info(f"tool_calls ê¸¸ì´: {len(tool_calls)}")
        if tool_calls:
            for i, call in enumerate(tool_calls):
                logger.info(f"tool_call[{i}]: {call.server_name}.{call.tool_name} = {call.result}")
        else:
            logger.info("tool_callsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        
        llm = get_llm()
        
        # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_message = """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë§Œì•½ ì™¸ë¶€ ë„êµ¬(MCP ë„êµ¬)ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ ìˆë‹¤ë©´, ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´, ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ìµœì„ ì˜ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì‘ë‹µ í˜•ì‹**: 
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì ì ˆí•œ ì œëª©(##), ëª©ë¡(-), ê°•ì¡°(**í…ìŠ¤íŠ¸**), ì½”ë“œ(`ì½”ë“œ`) ë“±ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì •ë³´ê°€ ë§ì„ ë•ŒëŠ” êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

        messages = [SystemMessage(content=system_message)]
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_input = state.get("current_message", BaseMessage(content="", type="human")).content
        
        # ê¸°ë³¸ ì‚¬ìš©ì ì»¨í…ì¸  ì´ˆê¸°í™”
        user_content = f"ì‚¬ìš©ì ì§ˆë¬¸: {user_input}"
        
        # MCP ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì¶”ê°€
        if tool_calls:
            user_content += "\n\në„êµ¬ ì‹¤í–‰ ê²°ê³¼:"
            for i, mcp_call in enumerate(tool_calls):
                if mcp_call.is_successful():
                    user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: {mcp_call.result}"
                else:
                    user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: ì˜¤ë¥˜ - {mcp_call.error}"
            
            # ë„êµ¬ í˜¸ì¶œ ì •ë³´ ìš”ì•½ ì¶”ê°€
            user_content += "\n\nì‚¬ìš©ëœ ë„êµ¬:"
            for mcp_call in tool_calls:
                user_content += f"\n- {mcp_call.server_name}.{mcp_call.tool_name}({mcp_call.arguments})"
        
        messages.append(HumanMessage(content=user_content))
        
        # ë””ë²„ê¹…: LLMì— ì „ë‹¬ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ë‚´ìš© ì¶œë ¥
        logger.info(f"LLMì— ì „ë‹¬ë˜ëŠ” í”„ë¡¬í”„íŠ¸:")
        logger.info(f"ì‹œìŠ¤í…œ ë©”ì‹œì§€: {system_message}")
        logger.info(f"ì‚¬ìš©ì ì»¨í…ì¸ : {user_content}")
        
        # LLM ì‘ë‹µ ìƒì„±
        response = llm.invoke(messages)
        generated_response = response.content
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["response"] = generated_response
        state["success"] = True
        update_workflow_step(state, "completed")
        
        logger.info("LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        return state
        
    except Exception as e:
        logger.error(f"LLM ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        logger.info("ê¸°ì¡´ ë°©ì‹ ì‘ë‹µ ìƒì„±ìœ¼ë¡œ í´ë°±")
        update_workflow_step(state, "generate_response")
        return state


def _parse_llm_intent_response(response_text: str, user_input: str) -> ParsedIntent:
    """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ParsedIntent ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤
    
    Args:
        response_text: LLMì˜ ì›ì‹œ ì‘ë‹µ í…ìŠ¤íŠ¸
        user_input: ì›ë³¸ ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        íŒŒì‹±ëœ ì˜ë„ ê°ì²´
    """
    try:
        lines = response_text.strip().split('\n')
        intent_type_str = "GENERAL_CHAT"
        confidence = 0.5
        parameters = {}
        
        for line in lines:
            line = line.strip()
            if line.startswith("INTENT:"):
                intent_type_str = line.replace("INTENT:", "").strip()
            elif line.startswith("CONFIDENCE:"):
                try:
                    confidence = float(line.replace("CONFIDENCE:", "").strip())
                except ValueError:
                    confidence = 0.5
            elif line.startswith("PARAMETERS:"):
                param_str = line.replace("PARAMETERS:", "").strip()
                try:
                    import json
                    parameters = json.loads(param_str)
                except (json.JSONDecodeError, ValueError):
                    parameters = {}
        
        # IntentTypeìœ¼ë¡œ ë³€í™˜
        try:
            intent_type = IntentType(intent_type_str)
        except ValueError:
            intent_type = IntentType.GENERAL_CHAT
        
        # ëŒ€ìƒ ì„œë²„ì™€ ë„êµ¬ ê²°ì •
        target_server, target_tool = _determine_target_from_intent(intent_type, parameters)
        
        return ParsedIntent(
            intent_type=intent_type,
            confidence=confidence,
            parameters=parameters,
            target_server=target_server,
            target_tool=target_tool
        )
        
    except Exception as e:
        logger.warning(f"LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return ParsedIntent(
            intent_type=IntentType.GENERAL_CHAT,
            confidence=0.3,
            parameters={},
            target_server=None,
            target_tool=None
        )


def _determine_target_from_intent(intent_type: IntentType, parameters: Dict[str, Any]) -> tuple[Optional[str], Optional[str]]:
    """ì˜ë„ì™€ ë§¤ê°œë³€ìˆ˜ë¡œë¶€í„° ëŒ€ìƒ ì„œë²„ì™€ ë„êµ¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤"""
    if intent_type == IntentType.WEATHER_QUERY:
        if parameters.get('forecast'):
            return 'weather', 'get_forecast'
        else:
            return 'weather', 'get_weather'
    
    elif intent_type == IntentType.FILE_OPERATION:
        operation = parameters.get('operation', 'list')
        tool_map = {
            'list': 'list_files',
            'read': 'read_file', 
            'info': 'file_info'
        }
        return 'file-manager', tool_map.get(operation, 'list_files')
    
    elif intent_type in [IntentType.TOOL_LIST, IntentType.SERVER_STATUS, IntentType.HELP, IntentType.GENERAL_CHAT]:
        # ì´ëŸ¬í•œ ìš”ì²­ë“¤ì€ MCP ë„êµ¬ í˜¸ì¶œì´ ì•„ë‹Œ ì‹œìŠ¤í…œ ì •ë³´ ì œê³µ
        return None, None
    
    return None, None


class StreamingCallbackHandler(BaseCallbackHandler):
    """í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""
    
    def __init__(self, sse_manager, session_id: str):
        self.sse_manager = sse_manager
        self.session_id = session_id
        self.current_content = ""
        self.token_count = 0
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """ìƒˆ í† í°ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ í˜¸ì¶œ"""
        if token and token.strip():  # ê³µë°± í† í° ë¬´ì‹œ
            self.current_content += token
            self.token_count += 1
            
            # ë§¤ 3ê°œ í† í°ë§ˆë‹¤ ì „ì†¡
            if self.token_count % 3 == 0:
                self._send_partial_update_sync()
    
    def on_llm_end(self, response, **kwargs) -> None:
        """LLM ì‘ë‹µ ì™„ë£Œ ì‹œ ë§ˆì§€ë§‰ í† í°ë“¤ ì „ì†¡"""
        if self.current_content:
            self._send_partial_update_sync()
    
    def _send_partial_update_sync(self):
        """ë¶€ë¶„ ì—…ë°ì´íŠ¸ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì „ì†¡"""
        try:
            from ..streaming import create_partial_response_message
            
            partial_msg = create_partial_response_message(
                self.current_content,
                self.session_id
            )
            
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì „ì†¡
            import asyncio
            import threading
            
            def send_message():
                try:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    loop.run_until_complete(
                        self.sse_manager.send_to_session(self.session_id, partial_msg)
                    )
                    loop.close()
                except Exception as e:
                    import logging
                    logger = logging.getLogger(__name__)
                    logger.warning(f"ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            thread = threading.Thread(target=send_message, daemon=True)
            thread.start()
            
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.warning(f"ë¶€ë¶„ ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨: {e}")


async def llm_generate_response_with_streaming(state: ChatState, sse_manager, session_id: str) -> ChatState:
    """í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ê³¼ í•¨ê»˜ LLM ì‘ë‹µ ìƒì„± (ë©€í‹°í„´ ëŒ€í™” ì§€ì›)"""
    try:
        increment_step_count(state)
        logger.info("LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹œì‘ (ë©€í‹°í„´ ëŒ€í™” í¬í•¨)")
        
        user_input = state.get("current_message", BaseMessage(content="", type="human")).content
        tool_calls = state.get("tool_calls", [])
        parsed_intent = state.get("parsed_intent")
        
        logger.info(f"ì‚¬ìš©ì ì…ë ¥: {user_input}")
        logger.info(f"íŒŒì‹±ëœ ì˜ë„: {parsed_intent.intent_type if parsed_intent else 'None'}")
        logger.info(f"ë„êµ¬ í˜¸ì¶œ ìˆ˜: {len(tool_calls)}")
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì‘ë‹µ ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        if parsed_intent and parsed_intent.intent_type in [IntentType.TOOL_LIST, IntentType.SERVER_STATUS]:
            logger.info("ì‹œìŠ¤í…œ ì •ë³´ ì‘ë‹µìœ¼ë¡œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            return llm_generate_response(state)  # ì‹œìŠ¤í…œ ì •ë³´ëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        
        logger.info("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì§„í–‰")
        
        # ì¼ë°˜ LLM ì‚¬ìš© (ìŠ¤íŠ¸ë¦¬ë° ì—†ì´)
        llm = get_llm()
        
        # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
        system_message = """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ì˜ ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ í†µí•´ ë§¥ë½ì„ ì´í•´í•˜ê³  ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ëŒ€í™” ë§¥ë½ í™œìš©**:
- ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ "ê·¸ê²ƒ", "ê·¸ê±°", "ìœ„ì—ì„œ ë§í•œ" ë“±ìœ¼ë¡œ ì´ì „ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ë©´ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”
- ì—°ê´€ëœ ì£¼ì œë‚˜ í›„ì† ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë§¥ë½ì„ ìœ ì§€í•˜ì„¸ìš”

**ë„êµ¬ ê²°ê³¼ í™œìš©**:
- ì™¸ë¶€ ë„êµ¬(MCP ë„êµ¬) ê²°ê³¼ê°€ ìˆë‹¤ë©´, ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”
- ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´, ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ìµœì„ ì˜ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”

**ì‘ë‹µ í˜•ì‹**: 
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì ì ˆí•œ ì œëª©(##), ëª©ë¡(-), ê°•ì¡°(**í…ìŠ¤íŠ¸**), ì½”ë“œ(`ì½”ë“œ`) ë“±ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì •ë³´ê°€ ë§ì„ ë•ŒëŠ” êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”"""

        messages = [SystemMessage(content=system_message)]
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì¶”ê°€
        conversation_history = state.get("messages", [])
        logger.info(f"ëŒ€í™” íˆìŠ¤í† ë¦¬: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
        
        if len(conversation_history) > 1:  # í˜„ì¬ ë©”ì‹œì§€ ì™¸ì— ì´ì „ ë©”ì‹œì§€ê°€ ìˆëŠ” ê²½ìš°
            logger.info("ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨")
            
            # ì´ì „ ë©”ì‹œì§€ë“¤ (í˜„ì¬ ë©”ì‹œì§€ ì œì™¸)ì„ LLM ë©”ì‹œì§€ë¡œ ë³€í™˜
            for msg in conversation_history[:-1]:  # ë§ˆì§€ë§‰ ë©”ì‹œì§€(í˜„ì¬ ë©”ì‹œì§€) ì œì™¸
                if msg.role == MessageRole.USER:
                    messages.append(HumanMessage(content=msg.content))
                elif msg.role == MessageRole.ASSISTANT:
                    messages.append(AIMessage(content=msg.content))
                # TOOL ë©”ì‹œì§€ëŠ” ìŠ¤í‚µ (LLM ë©”ì‹œì§€ íƒ€ì…ì— ì—†ìŒ)
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ë° ë„êµ¬ ê²°ê³¼ ì¶”ê°€
        current_user_content = f"ì‚¬ìš©ì ì§ˆë¬¸: {user_input}"
        
        # MCP ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì¶”ê°€
        if tool_calls:
            current_user_content += "\n\në°©ê¸ˆ ì‹¤í–‰ëœ ë„êµ¬ ê²°ê³¼:"
            for i, mcp_call in enumerate(tool_calls):
                if mcp_call.is_successful():
                    current_user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: {mcp_call.result}"
                else:
                    current_user_content += f"\n{i+1}. {mcp_call.server_name}.{mcp_call.tool_name}: ì˜¤ë¥˜ - {mcp_call.error}"
            
            # ë„êµ¬ í˜¸ì¶œ ì •ë³´ ìš”ì•½ ì¶”ê°€
            current_user_content += "\n\nì‚¬ìš©ëœ ë„êµ¬:"
            for mcp_call in tool_calls:
                current_user_content += f"\n- {mcp_call.server_name}.{mcp_call.tool_name}({mcp_call.arguments})"
        
        messages.append(HumanMessage(content=current_user_content))
        
        logger.info(f"LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ ìˆ˜: {len(messages)} (ì‹œìŠ¤í…œ: 1, íˆìŠ¤í† ë¦¬: {len(conversation_history)-1}, í˜„ì¬: 1)")
        
        logger.info("LLM ì‘ë‹µ ìƒì„± ì¤‘...")
        # ë¨¼ì € ì „ì²´ ì‘ë‹µ ìƒì„±
        response = await llm.ainvoke(messages)
        generated_response = response.content
        
        logger.info(f"LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ, ê¸¸ì´: {len(generated_response)}")
        logger.info(f"ì‘ë‹µ ì¼ë¶€: {generated_response[:100]}...")
        
        # ë¬¸ì ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³€ê²½ (ìµœì†Œ ë‹¨ìœ„)
        current_text = ""
        char_count = 0
        
        logger.info(f"ë¬¸ì ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘, ì´ {len(generated_response)}ê¸€ì")
        
        for i, char in enumerate(generated_response):
            current_text += char
            char_count += 1
            
            # 1-2 ê¸€ìë§ˆë‹¤ ë˜ëŠ” êµ¬ë‘ì ë§ˆë‹¤ partial_response ì „ì†¡ (ìµœì†Œ ë‹¨ìœ„)
            should_send = (
                char_count % 1 == 0 or  # ê±°ì˜ ëª¨ë“  ê¸€ìë§ˆë‹¤ (ì‹¤ì‹œê°„ íš¨ê³¼ ê·¹ëŒ€í™”)
                char in [' ', '\n', '.', ',', '!', '?', ';', ':', '-', ')', ']', '}'] or  # êµ¬ë‘ì ì´ë‚˜ ê³µë°±
                i == len(generated_response) - 1  # ë§ˆì§€ë§‰ ê¸€ì
            )
            
            if should_send:
                # 10ê¸€ìë§ˆë‹¤ë§Œ ë¡œê¹… (ë¡œê·¸ ê³¼ë¶€í•˜ ë°©ì§€)
                if i % 10 == 0 or i == len(generated_response) - 1:
                    logger.info(f"partial_response ì „ì†¡ ì¤‘... ({i+1}/{len(generated_response)})")
                    
                from ..streaming import create_partial_response_message
                partial_msg = create_partial_response_message(current_text.strip(), session_id)
                
                try:
                    await sse_manager.send_to_session(session_id, partial_msg)
                    # ì„±ê³µ ë¡œê·¸ë„ ê°„ì†Œí™”
                    if i % 20 == 0 or i == len(generated_response) - 1:
                        logger.info(f"partial_response ì „ì†¡ ì„±ê³µ: {len(current_text.strip())} ê¸€ì")
                except Exception as e:
                    logger.error(f"partial_response ì „ì†¡ ì‹¤íŒ¨: {e}")
                
                # ì‹¤ì‹œê°„ íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•œ ì•„ì£¼ ì§§ì€ ì§€ì—°
                if char in [' ', '\n']:
                    await asyncio.sleep(0.02)  # ê³µë°±/ì¤„ë°”ê¿ˆ ì‹œ ì§§ì€ ì§€ì—°
                elif char in ['.', '!', '?']:
                    await asyncio.sleep(0.1)   # ë¬¸ì¥ ë ì‹œ ì•½ê°„ ê¸´ ì§€ì—°
                else:
                    await asyncio.sleep(0.01)  # ì¼ë°˜ ê¸€ìëŠ” ê·¹ë„ë¡œ ì§§ì€ ì§€ì—°
        
        logger.info("ëª¨ë“  partial_response ì „ì†¡ ì™„ë£Œ")
        
        # ìµœì¢… ì‘ë‹µìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
        state["response"] = generated_response
        state["success"] = True
        update_workflow_step(state, "completed")
        
        # ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥ (ì¤‘ìš”!)
        from .state import add_assistant_message
        add_assistant_message(state, generated_response)
        
        # ìµœì¢… ì‘ë‹µ ë©”ì‹œì§€ ì „ì†¡
        logger.info("final_response ì „ì†¡ ì¤‘...")
        from ..streaming import create_final_response_message
        final_msg = create_final_response_message(generated_response, session_id)
        try:
            await sse_manager.send_to_session(session_id, final_msg)
            logger.info("final_response ì „ì†¡ ì„±ê³µ")
        except Exception as e:
            logger.error(f"final_response ì „ì†¡ ì‹¤íŒ¨: {e}")
        
        logger.info("LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        return state
        
    except Exception as e:
        logger.error(f"LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        return llm_generate_response(state) 