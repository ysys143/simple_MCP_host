# LangGraph MCP í˜¸ìŠ¤íŠ¸ MVP êµ¬í˜„ ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œ

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ëª©ì 
MCP Python SDKì™€ LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ëª‡ ì‹œê°„ ì•ˆì— êµ¬í˜„ ê°€ëŠ¥í•œ **LLM ê¸°ë°˜ MCP í˜¸ìŠ¤íŠ¸ ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•œë‹¤. OpenAI ChatGPTë¥¼ í™œìš©í•œ ìì—°ì–´ ì´í•´ì™€ ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ MCP ë„êµ¬ í˜¸ì¶œì„ í†µí•´ ì‚¬ìš©ìê°€ ì±„íŒ…ìœ¼ë¡œ ì™¸ë¶€ MCP ì„œë²„ì˜ ë„êµ¬ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì¤‘ê°„ ê³„ì¸µì„ ì œê³µí•œë‹¤.

### 1.2 MVP ë²”ìœ„
- **í¬í•¨ì‚¬í•­**: 
  - LLM ê¸°ë°˜ ìì—°ì–´ ì´í•´ (OpenAI ChatGPT)
  - í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ì‹œìŠ¤í…œ
  - Enhanced MCP í´ë¼ì´ì–¸íŠ¸ (langchain-mcp-adapters)
  - LangGraph í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš°
  - ì›¹ ì±„íŒ… UI, FastAPI ë°±ì—”ë“œ
- **ì™¸ë¶€ ì˜ì¡´ì„±**: ë³„ë„ ë ˆí¬ì§€í† ë¦¬ì˜ ë‚ ì”¨ MCP ì„œë²„, OpenAI API
- **ì œì™¸ì‚¬í•­**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°, Docker, ê´€ì°°ì„±, ë³µì¡í•œ UI, ì¸ì¦, ë°ì´í„°ë² ì´ìŠ¤

## 2. ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­

### 2.1 í•µì‹¬ ê¸°ëŠ¥ (MVP)

#### 2.1.1 LLM ê¸°ë°˜ ìì—°ì–´ ì´í•´
- **FR-001**: OpenAI ChatGPTë¥¼ í™œìš©í•œ ì‚¬ìš©ì ì˜ë„ ë¶„ì„
- **FR-002**: ìì—°ì–´ ìš”ì²­ì˜ ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ ë° êµ¬ì¡°í™”
- **FR-003**: ì˜ë„ ë¶„ë¥˜ (ë‚ ì”¨, íŒŒì¼ ì‘ì—…, ì„œë²„ ìƒíƒœ, ë„ì›€ë§, ì¼ë°˜ ëŒ€í™”)
- **FR-004**: LLM ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ì‹œìŠ¤í…œ

#### 2.1.2 Enhanced MCP í˜¸ìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸
- **FR-005**: langchain-mcp-adapters ê¸°ë°˜ MCP í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
- **FR-006**: ì™¸ë¶€ MCP ì„œë²„ ì—°ê²° ê´€ë¦¬ (stdio í”„ë¡œí† ì½œ)
- **FR-007**: MCP ë„êµ¬ ë°œê²¬ ë° ìë™ ë³€í™˜ (load_mcp_tools)
- **FR-008**: MCP ë„êµ¬ í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬

#### 2.1.3 LangGraph í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš°
- **FR-009**: StateGraph ê¸°ë°˜ LLM + í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš°
- **FR-010**: LLM ì˜ë„ ë¶„ì„ ë…¸ë“œ (llm_parse_intent)
- **FR-011**: LLM MCP ë„êµ¬ í˜¸ì¶œ ë…¸ë“œ (llm_call_mcp_tool)
- **FR-012**: LLM ì‘ë‹µ ìƒì„± ë…¸ë“œ (llm_generate_response)
- **FR-013**: í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë…¸ë“œë“¤ (parse_message, call_mcp_tool, generate_response)

#### 2.1.4 ì›¹ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
- **FR-014**: ê°„ë‹¨í•œ HTML/JavaScript ì±„íŒ… UI
- **FR-015**: WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ë©”ì‹œì§€ ì†¡ìˆ˜ì‹ 
- **FR-016**: ì—°ê²°ëœ MCP ì„œë²„ ë° ë„êµ¬ ëª©ë¡ í‘œì‹œ

#### 2.1.5 FastAPI ë°±ì—”ë“œ
- **FR-017**: WebSocket ì—”ë“œí¬ì¸íŠ¸ (/ws)
- **FR-018**: LangGraph í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
- **FR-019**: Enhanced MCP Clientì™€ LLM ì›Œí¬í”Œë¡œìš° ì—°ê²°

#### 2.1.6 ì™¸ë¶€ MCP ì„œë²„ ì—°ë™
- **FR-020**: ì„¤ì • íŒŒì¼ ê¸°ë°˜ MCP ì„œë²„ ëª©ë¡ ê´€ë¦¬
- **FR-021**: ë™ì  MCP ì„œë²„ ì—°ê²°/í•´ì œ
- **FR-022**: MCP ì„œë²„ ìƒíƒœ ëª¨ë‹ˆí„°ë§

## 3. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 3.1 LLM ê¸°ë°˜ MCP í˜¸ìŠ¤íŠ¸ êµ¬ì¡°
```
ì›¹ ë¸Œë¼ìš°ì € (ì±„íŒ… UI)
       â†• WebSocket
FastAPI ì„œë²„ (MCP í˜¸ìŠ¤íŠ¸)
       â†• LangGraph í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš°
       â”œâ”€ LLM ê¸°ë°˜ (OpenAI ChatGPT)
       â”‚  â”œâ”€ llm_parse_intent
       â”‚  â”œâ”€ llm_call_mcp_tool  
       â”‚  â””â”€ llm_generate_response
       â””â”€ í‚¤ì›Œë“œ ê¸°ë°˜ (í´ë°±)
          â”œâ”€ parse_message
          â”œâ”€ call_mcp_tool
          â””â”€ generate_response
       â†• Enhanced MCP Client (langchain-mcp-adapters)
ì™¸ë¶€ MCP ì„œë²„ë“¤ (ë³„ë„ ë ˆí¬)
â”œâ”€â”€ weather-mcp-server
â”œâ”€â”€ file-mcp-server  
â””â”€â”€ api-mcp-server
```

### 3.2 ë ˆí¬ì§€í† ë¦¬ êµ¬ì¡°
```
# ì´ ë ˆí¬ì§€í† ë¦¬ (MCP í˜¸ìŠ¤íŠ¸)
MCP_test/
â”œâ”€â”€ mcp_host/
â”‚   â”œâ”€â”€ __main__.py          # CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â””â”€â”€ enhanced_client.py # Enhanced MCP Client
â”‚   â”œâ”€â”€ config.py            # MCP ì„œë²„ ì„¤ì •
â”‚   â”œâ”€â”€ models.py            # ë°ì´í„° ëª¨ë¸ (Pydantic)
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ executor.py      # í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ê¸°
â”‚   â”‚   â”œâ”€â”€ nodes.py         # í‚¤ì›Œë“œ ê¸°ë°˜ ë…¸ë“œë“¤
â”‚   â”‚   â”œâ”€â”€ llm_nodes.py     # LLM ê¸°ë°˜ ë…¸ë“œë“¤
â”‚   â”‚   â””â”€â”€ state_utils.py   # ìƒíƒœ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ app.py           # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ run_tests.py     # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_config.py
â”‚       â”œâ”€â”€ test_enhanced_client.py  
â”‚       â”œâ”€â”€ test_workflow.py
â”‚       â””â”€â”€ test_llm_workflow.py     # LLM í…ŒìŠ¤íŠ¸
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html          # ì±„íŒ… UI
â”œâ”€â”€ app.py                  # FastAPI ì„œë²„ ëŸ°ì²˜
â”œâ”€â”€ main.py                 # uvicorn ì„œë²„ ëŸ°ì²˜
â”œâ”€â”€ mcp_servers.json        # MCP ì„œë²„ ì„¤ì •
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile               # í¸ë¦¬í•œ ëª…ë ¹ì–´
â””â”€â”€ README.md

# ë³„ë„ ë ˆí¬ì§€í† ë¦¬ (ì˜ˆì‹œ)
weather-mcp-server/
â”œâ”€â”€ server.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### 3.3 MCP ì„œë²„ ì„¤ì • íŒŒì¼
```json
{
  "servers": {
    "weather": {
      "command": "python",
      "args": ["/path/to/weather-mcp-server/server.py"],
      "env": {}
    },
    "file-manager": {
      "command": "python", 
      "args": ["/path/to/file-mcp-server/server.py"],
      "env": {}
    }
  }
}
```

## 4. êµ¬í˜„ ì‚¬ì–‘

### 4.1 LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„ (llm_nodes.py)
```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

def get_llm() -> ChatOpenAI:
    """ChatOpenAI LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (ì‹±ê¸€í†¤)"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    return ChatOpenAI(
        model="gpt-4o-mini",  # ë¹ ë¥´ê³  ê²½ì œì ì¸ ëª¨ë¸
        temperature=0.1,      # ì¼ê´€ëœ ì‘ë‹µ
        max_tokens=1000,      # ì ì ˆí•œ ì‘ë‹µ ê¸¸ì´
    )

def llm_parse_intent(state: ChatState) -> ChatState:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤"""
    user_input = state["current_message"].content
    
    # ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸
    intent_prompt = ChatPromptTemplate.from_messages([
        ("system", """ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”:
1. WEATHER_QUERY: ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸
2. FILE_OPERATION: íŒŒì¼/ë””ë ‰í† ë¦¬ ì‘ì—…
3. SERVER_STATUS: MCP ì„œë²„ ìƒíƒœ í™•ì¸
4. TOOL_LIST: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ìš”ì²­
5. HELP: ë„ì›€ë§ì´ë‚˜ ì‚¬ìš©ë²• ë¬¸ì˜
6. GENERAL_CHAT: ì¼ë°˜ì ì¸ ëŒ€í™”

ì‘ë‹µ í˜•ì‹:
INTENT: [ì˜ë„]
CONFIDENCE: [0.0-1.0 ì‹ ë¢°ë„]
PARAMETERS: [JSON í˜•ì‹ ë§¤ê°œë³€ìˆ˜]
REASONING: [ë¶„ë¥˜ ê·¼ê±°]"""),
        ("human", "{user_input}")
    ])
    
    llm = get_llm()
    response = (intent_prompt | llm).invoke({"user_input": user_input})
    
    # ì‘ë‹µ íŒŒì‹±í•˜ì—¬ ParsedIntent ìƒì„±
    parsed_intent = _parse_llm_intent_response(response.content, user_input)
    state["parsed_intent"] = parsed_intent
    
    # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
    if parsed_intent.is_mcp_action():
        state["next_step"] = "llm_call_mcp_tool"
    else:
        state["next_step"] = "llm_generate_response"
    
    return state
```

### 4.2 Enhanced MCP Client (enhanced_client.py)
```python
from langchain_mcp_adapters import MultiServerMCPClient
from mcp_host.config import create_config_manager

class EnhancedMCPClient:
    """langchain-mcp-adapters ê¸°ë°˜ í–¥ìƒëœ MCP í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
        self.mcp_client = None
        self.available_tools = {}
    
    async def connect(self):
        """ëª¨ë“  ì„¤ì •ëœ MCP ì„œë²„ì— ì—°ê²°"""
        server_configs = self.config_manager.get_all_server_configs()
        
        # MultiServerMCPClient ì´ˆê¸°í™”
        self.mcp_client = MultiServerMCPClient()
        
        for server_name, config in server_configs.items():
            try:
                await self.mcp_client.add_server(
                    server_name,
                    command=config["command"],
                    args=config["args"]
                )
                logger.info(f"âœ… {server_name} ì„œë²„ ì—°ê²° ì„±ê³µ")
            except Exception as e:
                logger.error(f"âŒ {server_name} ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¡œë“œ
        await self._load_available_tools()
    
    async def _load_available_tools(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤"""
        from langchain_mcp_adapters import load_mcp_tools
        
        try:
            tools = await load_mcp_tools(self.mcp_client)
            self.available_tools = {tool.name: tool for tool in tools}
            logger.info(f"ë¡œë“œëœ ë„êµ¬: {list(self.available_tools.keys())}")
        except Exception as e:
            logger.error(f"ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
```

### 4.3 í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° (executor.py)
```python
from langgraph.graph import StateGraph, END
from .nodes import parse_message, call_mcp_tool, generate_response
from .llm_nodes import llm_parse_intent, llm_call_mcp_tool, llm_generate_response

def create_workflow_executor() -> MCPWorkflowExecutor:
    """LLMê³¼ í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    workflow = StateGraph(ChatState)
    
    # === LLM ê¸°ë°˜ ë…¸ë“œë“¤ (ê¸°ë³¸) ===
    workflow.add_node("llm_parse_intent", llm_parse_intent)
    workflow.add_node("llm_call_mcp_tool", llm_call_mcp_tool) 
    workflow.add_node("llm_generate_response", llm_generate_response)
    
    # === í‚¤ì›Œë“œ ê¸°ë°˜ ë…¸ë“œë“¤ (í´ë°±ìš©) ===
    workflow.add_node("parse_message", parse_message)
    workflow.add_node("call_mcp_tool", call_mcp_tool)
    workflow.add_node("generate_response", generate_response)
    
    # === ì§„ì…ì ê³¼ íë¦„ ì„¤ì • ===
    workflow.set_entry_point("llm_parse_intent")  # LLM ìš°ì„  ì‹œë„
    
    # LLM ê¸°ë°˜ íë¦„
    workflow.add_conditional_edges(
        "llm_parse_intent",
        _decide_next_step,
        {
            "llm_call_mcp_tool": "llm_call_mcp_tool",
            "llm_generate_response": "llm_generate_response", 
            "parse_message": "parse_message",  # í´ë°±
        }
    )
    
    workflow.add_edge("llm_call_mcp_tool", "llm_generate_response")
    workflow.add_edge("llm_generate_response", END)
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± íë¦„
    workflow.add_conditional_edges(
        "parse_message",
        _decide_next_step,
        {
            "call_mcp_tool": "call_mcp_tool",
            "generate_response": "generate_response",
        }
    )
    
    workflow.add_edge("call_mcp_tool", "generate_response")
    workflow.add_edge("generate_response", END)
    
    return MCPWorkflowExecutor(workflow.compile())
```

### 4.4 FastAPI í˜¸ìŠ¤íŠ¸ (services/app.py)
```python
from fastapi import FastAPI, WebSocket
from mcp_host.workflows import create_workflow_executor
from mcp_host.adapters.enhanced_client import EnhancedMCPClient

class MCPHostApp:
    """MCP í˜¸ìŠ¤íŠ¸ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self):
        self.app = FastAPI(title="LangGraph MCP í˜¸ìŠ¤íŠ¸")
        self.mcp_client = None
        self.workflow_executor = None
        
    async def startup(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
        # Enhanced MCP Client ì´ˆê¸°í™”
        config_manager = create_config_manager()
        self.mcp_client = EnhancedMCPClient(config_manager)
        await self.mcp_client.connect()
        
        # LLM í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ê¸° ìƒì„±
        self.workflow_executor = create_workflow_executor()
        
    @app.websocket("/ws")
    async def websocket_endpoint(websocket: WebSocket):
        await websocket.accept()
        
        while True:
            message = await websocket.receive_text()
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = await self.workflow_executor.execute_message(
                user_message=message,
                session_id="websocket_session",
                mcp_client=self.mcp_client
            )
            
            await websocket.send_text(result["response"])
```

### 4.5 í”„ë¡ íŠ¸ì—”ë“œ (static/index.html)
```html
<!DOCTYPE html>
<html>
<head>
    <title>LangGraph MCP í˜¸ìŠ¤íŠ¸ (LLM ê¸°ë°˜)</title>
    <style>
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; padding: 20px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        .container {
            max-width: 800px; margin: 0 auto;
            background: white; border-radius: 12px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            overflow: hidden;
        }
        .header {
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            color: white; padding: 20px; text-align: center;
        }
        #messages { 
            height: 400px; overflow-y: auto; 
            padding: 20px; background: #f8f9fa;
        }
        .message {
            margin: 10px 0; padding: 12px;
            border-radius: 8px; max-width: 80%;
        }
        .user-message { 
            background: #007bff; color: white;
            margin-left: auto; text-align: right;
        }
        .bot-message { 
            background: #e9ecef; color: #333;
        }
        .input-area {
            padding: 20px; background: white;
            border-top: 1px solid #dee2e6;
        }
        #messageInput { 
            width: calc(100% - 100px); padding: 12px;
            border: 2px solid #dee2e6; border-radius: 25px;
            font-size: 14px; outline: none;
        }
        #messageInput:focus { border-color: #007bff; }
        button { 
            width: 80px; padding: 12px; margin-left: 10px;
            background: #007bff; color: white; border: none;
            border-radius: 25px; cursor: pointer; font-weight: bold;
        }
        button:hover { background: #0056b3; }
        .commands {
            padding: 15px 20px; background: #fff3cd;
            border-top: 1px solid #ffeaa7; font-size: 13px;
        }
        .commands h4 { margin: 0 0 10px 0; color: #856404; }
        .command { 
            display: inline-block; margin: 3px 8px 3px 0;
            padding: 4px 8px; background: #007bff; color: white;
            border-radius: 12px; cursor: pointer; font-size: 12px;
        }
        .command:hover { background: #0056b3; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¤– LangGraph MCP í˜¸ìŠ¤íŠ¸</h1>
            <p>ChatGPT ê¸°ë°˜ ìì—°ì–´ ì´í•´ + MCP ë„êµ¬ í˜¸ì¶œ</p>
        </div>
        
        <div id="messages"></div>
        
        <div class="input-area">
            <input id="messageInput" type="text" 
                   placeholder="ìì—°ì–´ë¡œ ìš”ì²­í•´ë³´ì„¸ìš”... (ì˜ˆ: ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜)">
            <button onclick="sendMessage()">ì „ì†¡</button>
        </div>
        
        <div class="commands">
            <h4>ğŸ’¡ ëª…ë ¹ì–´ ì˜ˆì‹œ (í´ë¦­í•´ì„œ ì‚¬ìš©):</h4>
            <span class="command" onclick="sendCommand('ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?')">ë‚ ì”¨ ì¡°íšŒ</span>
            <span class="command" onclick="sendCommand('í˜„ì¬ ë””ë ‰í† ë¦¬ íŒŒì¼ ëª©ë¡ì„ ë³´ì—¬ì£¼ì„¸ìš”')">íŒŒì¼ ëª©ë¡</span>
            <span class="command" onclick="sendCommand('/servers')">ì„œë²„ ëª©ë¡</span>
            <span class="command" onclick="sendCommand('/tools')">ë„êµ¬ ëª©ë¡</span>
            <span class="command" onclick="sendCommand('ë„ì›€ë§ ë¶€íƒë“œë ¤ìš”')">ë„ì›€ë§</span>
        </div>
    </div>
    
    <script>
        const ws = new WebSocket('ws://localhost:8000/ws');
        const messages = document.getElementById('messages');
        
        ws.onmessage = function(event) {
            addMessage(event.data, 'bot');
        };
        
        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}-message`;
            messageDiv.innerHTML = text.replace(/\n/g, '<br>');
            messages.appendChild(messageDiv);
            messages.scrollTop = messages.scrollHeight;
        }
        
        function sendMessage() {
            const input = document.getElementById('messageInput');
            if (input.value.trim() === '') return;
            
            addMessage(input.value, 'user');
            ws.send(input.value);
            input.value = '';
        }
        
        function sendCommand(command) {
            document.getElementById('messageInput').value = command;
            sendMessage();
        }
        
        document.getElementById('messageInput').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') sendMessage();
        });
    </script>
</body>
</html>
```

## 5. ê°œë°œ ì¼ì • (4-5ì‹œê°„)

### 5.1 30ë¶„: MCP ì„œë²„ ì„¤ì • ì‹œìŠ¤í…œ âœ… ì™„ë£Œ
- config.py ë° mcp_servers.json êµ¬í˜„
- ì™¸ë¶€ MCP ì„œë²„ ì—°ê²° ë¡œì§

### 5.2 1ì‹œê°„: Enhanced MCP í´ë¼ì´ì–¸íŠ¸ âœ… ì™„ë£Œ  
- langchain-mcp-adapters í†µí•©
- ë‹¤ì¤‘ ì„œë²„ ì—°ê²° ê´€ë¦¬
- ìë™ ë„êµ¬ ë¡œë“œ ë° ë³€í™˜

### 5.3 2ì‹œê°„: LLM ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° âœ… ì™„ë£Œ
- LLM ë…¸ë“œ êµ¬í˜„ (ì˜ë„ ë¶„ì„, ë„êµ¬ í˜¸ì¶œ, ì‘ë‹µ ìƒì„±)
- í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ì‹œìŠ¤í…œ
- StateGraph í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±

### 5.4 1ì‹œê°„: FastAPI ë°±ì—”ë“œ ğŸš€ ì§„í–‰ì¤‘
- WebSocket ì—”ë“œí¬ì¸íŠ¸
- LLM ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—°ê²°

### 5.5 30ë¶„: í”„ë¡ íŠ¸ì—”ë“œ & í†µí•©
- í˜„ëŒ€ì  HTML/JavaScript ì±„íŒ… UI
- ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

## 6. ê¸°ìˆ  ìŠ¤íƒ

### 6.1 MCP í˜¸ìŠ¤íŠ¸
- **Python 3.11+**
- **OpenAI API**: ChatGPT LLM í†µí•© (gpt-4o-mini)
- **langchain-openai**: LLM ì¸í„°í˜ì´ìŠ¤
- **langchain-mcp-adapters**: Enhanced MCP í´ë¼ì´ì–¸íŠ¸  
- **LangGraph**: í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
- **FastAPI**: WebSocket ì§€ì›
- **uvicorn**: ASGI ì„œë²„
- **Pydantic**: ë°ì´í„° ê²€ì¦ ë° íƒ€ì… ì•ˆì „ì„±

### 6.2 ì™¸ë¶€ MCP ì„œë²„
- **ë³„ë„ ë ˆí¬ì§€í† ë¦¬**: weather-mcp-server ë“±
- **FastMCP**: MCP ì„œë²„ êµ¬í˜„
- **stdio í”„ë¡œí† ì½œ**: ì„œë²„ í†µì‹ 

### 6.3 ì˜ì¡´ì„±
```txt
# requirements.txt
mcp>=1.9.1
langchain>=0.3.25
langchain-core>=0.3.61
langchain-openai>=0.3.18      # LLM í†µí•©
langchain-mcp-adapters>=0.1.1  # Enhanced MCP Client
langgraph>=0.4.7
fastapi>=0.115.12
uvicorn>=0.34.2
pydantic>=2.11.5
pydantic-settings>=2.9.1
```

## 7. ì‹¤í–‰ ë°©ë²•

```bash
# 1. í™˜ê²½ ì„¤ì •
export OPENAI_API_KEY="your-openai-api-key-here"

# 2. ì˜ì¡´ì„± ì„¤ì¹˜ 
uv pip install -r requirements.txt

# 3. MCP ì„œë²„ ì„¤ì •
# mcp_servers.jsonì—ì„œ ì™¸ë¶€ MCP ì„œë²„ ê²½ë¡œ ì„¤ì •

# 4. MCP í˜¸ìŠ¤íŠ¸ ì‹¤í–‰
python -m mcp_host server
# ë˜ëŠ”
make server

# 5. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -m mcp_host test
# ë˜ëŠ”  
make test

# 6. LLM ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
python mcp_host/tests/test_llm_workflow.py

# 7. í”„ë¡ íŠ¸ì—”ë“œ ì ‘ì†
# http://localhost:8000/static/index.html
```

## 8. ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤

### 8.1 LLM ê¸°ë°˜ ìì—°ì–´ ëŒ€í™”
1. ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ `localhost:8000/static/index.html` ì ‘ì†
2. **"ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?"** ì…ë ¥
   - LLMì´ WEATHER_QUERY ì˜ë„ë¡œ ë¶„ì„
   - weather.get_weather ë„êµ¬ ìë™ í˜¸ì¶œ
   - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì‘ë‹µ ìƒì„±
3. **"í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆëŠ” íŒŒì¼ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”"** ì…ë ¥
   - LLMì´ FILE_OPERATION ì˜ë„ë¡œ ë¶„ì„  
   - file-manager.list_files ë„êµ¬ ìë™ í˜¸ì¶œ
4. **"íŒŒì´ì¬ê³¼ ìë°”ìŠ¤í¬ë¦½íŠ¸ì˜ ì°¨ì´ì ì´ ë­ì£ ?"** ì…ë ¥
   - LLMì´ GENERAL_CHATìœ¼ë¡œ ë¶„ë¥˜
   - ChatGPTê°€ ì§ì ‘ ë‹µë³€ ìƒì„±

### 8.2 í´ë°± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
1. OpenAI API í‚¤ ì—†ì´ ì‹¤í–‰
2. í‚¤ì›Œë“œ ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ìë™ í´ë°±
3. ê¸°ë³¸ ê¸°ëŠ¥ì€ ê³„ì† ë™ì‘

## 9. í™•ì¥ ê³„íš (MVP ì´í›„)

- **ë” ë§ì€ MCP ì„œë²„**: íŒŒì¼, API, ë°ì´í„°ë² ì´ìŠ¤ ë“±
- **ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€í™”**: ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- **ë©€í‹° ëª¨ë‹¬**: ì´ë¯¸ì§€, ìŒì„± ì§€ì›
- **ê³ ê¸‰ ì›Œí¬í”Œë¡œìš°**: ì¡°ê±´ë¶€ ë¶„ê¸°, ë©€í‹° ë„êµ¬ ì²´ì´ë‹
- **ë‹¤ë¥¸ LLM ì§€ì›**: Anthropic Claude, Google Gemini ë“±
- **React UI**: í˜„ëŒ€ì  í”„ë¡ íŠ¸ì—”ë“œ
- **Docker ì»¨í…Œì´ë„ˆí™”**

## 10. ê²°ë¡ 

ì´ MVPëŠ” **OpenAI ChatGPTë¥¼ í™œìš©í•œ ìì—°ì–´ ì´í•´**ì™€ **langchain-mcp-adapters ê¸°ë°˜ Enhanced MCP Client**ë¥¼ í†µí•´ ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì™¸ë¶€ MCP ì„œë²„ë“¤ê³¼ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” ì§€ëŠ¥í˜• í˜¸ìŠ¤íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. LLM ê¸°ë°˜ê³¼ í‚¤ì›Œë“œ ê¸°ë°˜ì˜ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ë¡œ ì•ˆì •ì„±ê³¼ í™•ì¥ì„±ì„ ëª¨ë‘ í™•ë³´í–ˆìŠµë‹ˆë‹¤.
